<!DOCTYPE html>
<html lang="en-US">
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link rel="stylesheet" href="/assets/css/style.css?v=1db909fa1f06ea7ae5dc1a7973fa98b17f58e65a" media="screen" type="text/css">
    <link rel="stylesheet" href="/assets/css/print.css" media="print" type="text/css">
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>参考 | hahadsg’s note</title>
<meta name="generator" content="Jekyll v3.9.3">
<meta property="og:title" content="参考">
<meta property="og:locale" content="en_US">
<link rel="canonical" href="https://hahadsg.github.io/bigdata/spark.html">
<meta property="og:url" content="https://hahadsg.github.io/bigdata/spark.html">
<meta property="og:site_name" content="hahadsg’s note">
<meta property="og:type" content="website">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="参考">
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","headline":"参考","url":"https://hahadsg.github.io/bigdata/spark.html"}</script>
<!-- End Jekyll SEO tag -->

  </head>

  <body>
    <header>
      <div class="inner">
        <a href="https://hahadsg.github.io/">
          <h1>hahadsg's note</h1>
        </a>
        <h2></h2>
        
        
          <a href="https://github.com/hahadsg" class="button"><small>Follow me on</small> GitHub</a>
        
      </div>
    </header>

    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">
          <h2 id="参考">参考</h2>

<p>http://litaotao.github.io/introduction-to-spark</p>

<h3 id="master-slave">master, slave</h3>

<p>master服务(YARN ResourceManager,Mesos master和Spark standalone master)决定哪些application可以运行，什么时候运行以及哪里去运行。而slave服务( YARN NodeManager, Mesos slave和Spark standalone slave)实际上运行executor进程。</p>

<h3 id="任务分配">任务分配</h3>

<p><strong>job</strong> : A job is triggered by an action, like count() or saveAsTextFile(). Click on a job to see information about the stages of tasks inside it.</p>

<p><strong>stage</strong> : stage 是一个 job 的组成单位，就是说，一个 job 会被切分成 1 个或 1 个以上的 stage，然后各个 stage 会按照执行顺序依次执行（以shuffle为界进行切分stage）</p>

<p><strong>task</strong> : A unit of work within a stage, corresponding to one RDD partition。即 stage 下的一个任务执行单元，一般来说，一个 rdd 有多少个 partition，就会有多少个 task，因为每一个 task 只是处理一个 partition 上的数据。从 web ui 截图上我们可以看到，这个 job 一共有 2 个 stage，66 个 task，平均下来每个 stage 有 33 个 task，相当于每个 stage 的数据都有 33 个 partition [注意：这里是平均下来的哦，并不都是每个 stage 有 33 个 task，有时候也会有一个 stage 多，另外一个 stage 少的情况，就看你有没有在不同的 stage 进行 repartition 类似的操作了。</p>

<h2 id="action-transformation">action, transformation</h2>

<p>判断结果会不会发到driver上，发到driver上的是action。比如reduce会产生一个结果发到driver上，就是action；reduceByKey对每个key进行操作，并不会发到driver上，就是transformation</p>

<h2 id="narrowwide-dependences">narrow/wide dependences</h2>

<p><img src="/bigdata/assets/spark/narrow%20and%20wide%20dependences.jpg" alt=""></p>

<p>narrow dependences: C-&gt;D，只使用至多一个partition</p>

<p>wide dependences: A-&gt;B，需要使用多个partitions，也就是说需要shuffle</p>

<h2 id="conf">Conf</h2>

<p>优先级：代码显示调用set；spark-submit传参；配置文件；系统默认值</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// print all config</span>
<span class="nv">spark</span><span class="o">.</span><span class="py">sparkContext</span><span class="o">.</span><span class="py">getConf</span><span class="o">.</span><span class="py">getAll</span><span class="o">.</span><span class="py">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>

<span class="c1">// set config by sql</span>
<span class="nv">spark</span><span class="o">.</span><span class="py">sql</span><span class="o">(</span><span class="s">"set spark.sql.shuffle.partitions=200"</span><span class="o">)</span> <span class="c1">// 设置sql发生shuffle后形成多少partitions</span>
</code></pre></div></div>

<h2 id="代码性能">代码性能</h2>

<ul>
  <li>调用函数</li>
</ul>

<p>错误的方法会将整个obj都发送到worker上</p>

<p>(关于实例化个人总结：将rdd作为示例的成员是没有问题的，如self.rdd；有问题的是df.map(self.f)这种情形)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">### wrong way
</span><span class="k">class</span> <span class="nc">SearchFunctions</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">):</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">query</span> <span class="o">=</span> <span class="n">query</span>
  <span class="k">def</span> <span class="nf">isMatch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
      <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">query</span> <span class="ow">in</span> <span class="n">s</span>
  <span class="k">def</span> <span class="nf">getMatchesFunctionReference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rdd</span><span class="p">):</span>
      <span class="c1"># Problem: references all of "self" in "self.isMatch"
</span>      <span class="k">return</span> <span class="n">rdd</span><span class="p">.</span><span class="nb">filter</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">isMatch</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">getMatchesMemberReference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rdd</span><span class="p">):</span>
      <span class="c1"># Problem: references all of "self" in "self.query"
</span>      <span class="k">return</span> <span class="n">rdd</span><span class="p">.</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="bp">self</span><span class="p">.</span><span class="n">query</span> <span class="ow">in</span> <span class="n">x</span><span class="p">)</span>
<span class="c1">### the right way
</span><span class="k">class</span> <span class="nc">WordFunctions</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
  <span class="p">...</span>
  <span class="k">def</span> <span class="nf">getMatchesNoReference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rdd</span><span class="p">):</span>
      <span class="c1"># Safe: extract only the field we need into a local variable
</span>      <span class="n">query</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">query</span>
      <span class="k">return</span> <span class="n">rdd</span><span class="p">.</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">query</span> <span class="ow">in</span> <span class="n">x</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li>broadcast</li>
</ul>

<p>https://blog.csdn.net/dengxing1234/article/details/74330768</p>

<h2 id="cpumemory设置">CPU/Memory设置</h2>

<p>http://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-2/</p>

<p>https://spark.apache.org/docs/latest/tuning.html</p>

<h3 id="tasks">tasks</h3>

<p>tasks数量是根据源数据的partition数量来的</p>

<p><strong>tasks过少时</strong></p>

<p>可能会导致executors跑不满（有些executeors闲置）</p>

<p>可能会导致，数据无法完全的放入到memory中（每个executors执行的tasks数量少，但是每次执行tasks所需内存大）</p>

<p><strong>如何设置</strong></p>

<p>通过实验的方式得到partitons数量，先用一个较小的值，每次*1.5，直到性能没有提升</p>

<h2 id="spark-streaming">Spark Streaming</h2>

<p>https://www.cnblogs.com/Dhouse/p/7615034.html</p>

<h2 id="todo">TODO</h2>

<p>怎么查看每个tasks是否完全放入到memory中</p>

        </section>

        <aside id="sidebar">
          

          

          <p>This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</p>

          <p>由于笔记大部分来自于我之前的gitbook，可能会因为markdown规范不同导致公式显示错误，如果有显示错误请<a href="https://github.com/hahadsg/hahadsg.github.io/issues">找我</a>，感谢</p>
        </aside>
      </div>
    </div>

    
  </body>
</html>
