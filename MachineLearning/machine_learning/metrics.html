<!DOCTYPE html>
<html lang="en-US">
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link rel="stylesheet" href="/assets/css/style.css?v=1db909fa1f06ea7ae5dc1a7973fa98b17f58e65a" media="screen" type="text/css">
    <link rel="stylesheet" href="/assets/css/print.css" media="print" type="text/css">
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>confusion matrix 混淆矩阵 | hahadsg’s note</title>
<meta name="generator" content="Jekyll v3.9.3">
<meta property="og:title" content="confusion matrix 混淆矩阵">
<meta property="og:locale" content="en_US">
<link rel="canonical" href="https://hahadsg.github.io/MachineLearning/machine_learning/metrics.html">
<meta property="og:url" content="https://hahadsg.github.io/MachineLearning/machine_learning/metrics.html">
<meta property="og:site_name" content="hahadsg’s note">
<meta property="og:type" content="website">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="confusion matrix 混淆矩阵">
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","headline":"confusion matrix 混淆矩阵","url":"https://hahadsg.github.io/MachineLearning/machine_learning/metrics.html"}</script>
<!-- End Jekyll SEO tag -->

  </head>

  <body>
    <header>
      <div class="inner">
        <a href="https://hahadsg.github.io/">
          <h1>hahadsg's note</h1>
        </a>
        <h2></h2>
        
        
          <a href="https://github.com/hahadsg" class="button"><small>Follow me on</small> GitHub</a>
        
      </div>
    </header>

    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">
          <h3 id="confusion-matrix-混淆矩阵">confusion matrix 混淆矩阵</h3>

<table>
  <thead>
    <tr>
      <th style="text-align: left"> </th>
      <th style="text-align: left">预测结果</th>
      <th style="text-align: left"> </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">真实情况</td>
      <td style="text-align: left">正例</td>
      <td style="text-align: left">反例</td>
    </tr>
    <tr>
      <td style="text-align: left">正例</td>
      <td style="text-align: left">TP（真正例）</td>
      <td style="text-align: left">FN（假反例）</td>
    </tr>
    <tr>
      <td style="text-align: left">反例</td>
      <td style="text-align: left">FP（假正例）</td>
      <td style="text-align: left">TN（真反例）</td>
    </tr>
  </tbody>
</table>

\[TPR = \frac{TP}{TP+FN} = recall \\
TNR = \frac{TN}{FP+TN} \\
FNR = \frac{FN}{TP+FN} \\
FPR = \frac{FP}{FP+TN} \\\]

<h3 id="precision-精确率-查准率">precision 精确率 查准率</h3>

\[precision=\frac{TP}{TP+FP}\]

<p>分母就是预测为正的，预测出为正，其中实际为正的比例</p>

<h3 id="recall-召回率-查全率">recall 召回率 查全率</h3>

\[recall=\frac{TP}{TP+FN}\]

<p>分母就是实际为正的，实际为正，其中被预测为正的比例</p>

<h3 id="f1">F1</h3>

\[F1 
= \frac{1}{\frac{1}{2} \times (\frac{1}{P} + \frac{1}{R})}
= \frac{2\times P\times R}{P+R}\]

<p>其中，\(P=precision, R=recall\)</p>

<p>F1是基于precision和recall的调和平均值</p>

<p>https://github.com/hahadsg/Practice/blob/master/MachineLearning/python/metrics/F1_score.ipynb</p>

<h3 id="fbeta">Fbeta</h3>

\[Fbeta
= \frac{1}{\frac{1}{1+\beta^2} \times (\frac{1}{P} + \frac{\beta^2}{R})}
= \frac{(1+\beta^2)\times P\times R}{(\beta^2\times P)+R}\]

<p>其中，\(P=precision, R=recall\)</p>

<p>\(\beta=1\)时退化为标准的\(F1\)；\(\beta\lt 1\)时\(P\)有更大影响；\(\beta\gt 1\)时\(R\)有更大影响</p>

<h3 id="roc">ROC</h3>

<p>https://github.com/hahadsg/Practice/blob/master/MachineLearning/python/metrics/ROC.ipynb</p>

<p>纵轴是TPR，横轴是FPR</p>

<h3 id="ks">KS</h3>

\[KS = max(TPR - FPR)\]

<h3 id="cohens-kappa">Cohen’s Kappa</h3>

\[\kappa = \frac{p_o - p_e}{1 - p_e}
= 1 - \frac{1 - p_o}{1 - p_e}\]

<p>其中，
\(p_o = \frac{TP+TN}{TP+FP+FN+TN}\)</p>

\[marginal_a = \frac{(TP+FN)(TP+FP)}{TP+FP+FN+TN}\]

\[marginal_b = \frac{(TN+FN)(TN+FP)}{TP+FP+FN+TN}\]

\[p_e = marginal_a + marginal_b\]

<p>直观解释，\(p_o\)是准确率，\(p_e\)是baseline，也就是\(\kappa = 1 - \frac{error_{accuracy}}{error_{baseline}}\)</p>

<p>从这个角度看，当\(accuracy=baseline\)时，评分为0；当\(accuracy &lt; baseline\)时，评分为负数；当\(accuracy &gt; baseline\)时，评分为正数。也就是kappa衡量了准确率与baseline的差距</p>

<p>然后解释baseline是什么，它是一个基准线，假设一个二分类问题，正类占0.9，负类占0.1，如果预测的label中，正类占0.8，负类占0.2。那么随便进行预测的准确率是\(0.9*0.8+0.1*0.2=0.74\)，以这个值为基准线</p>

        </section>

        <aside id="sidebar">
          

          

          <p>This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</p>

          <p>由于笔记大部分来自于我之前的gitbook，可能会因为markdown规范不同导致公式显示错误，如果有显示错误请<a href="https://github.com/hahadsg/hahadsg.github.io/issues">找我</a>，感谢</p>
        </aside>
      </div>
    </div>

    
  </body>
</html>
