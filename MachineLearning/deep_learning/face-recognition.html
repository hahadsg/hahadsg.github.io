<!DOCTYPE html>
<html lang="en-US">
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link rel="stylesheet" href="/assets/css/style.css?v=1db909fa1f06ea7ae5dc1a7973fa98b17f58e65a" media="screen" type="text/css">
    <link rel="stylesheet" href="/assets/css/print.css" media="print" type="text/css">
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>metrics | hahadsg’s note</title>
<meta name="generator" content="Jekyll v3.9.3">
<meta property="og:title" content="metrics">
<meta property="og:locale" content="en_US">
<link rel="canonical" href="https://hahadsg.github.io/MachineLearning/deep_learning/face-recognition.html">
<meta property="og:url" content="https://hahadsg.github.io/MachineLearning/deep_learning/face-recognition.html">
<meta property="og:site_name" content="hahadsg’s note">
<meta property="og:type" content="website">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="metrics">
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","headline":"metrics","url":"https://hahadsg.github.io/MachineLearning/deep_learning/face-recognition.html"}</script>
<!-- End Jekyll SEO tag -->

  </head>

  <body>
    <header>
      <div class="inner">
        <a href="https://hahadsg.github.io/">
          <h1>hahadsg's note</h1>
        </a>
        <h2></h2>
        
        
          <a href="https://github.com/hahadsg" class="button"><small>Follow me on</small> GitHub</a>
        
      </div>
    </header>

    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">
          <h1 id="metrics">metrics</h1>

<p>1.FAR(False Accept Rate) 误识率：人脸对比通过但实际不是本人，把假的认成真的</p>

<p>2.VAL(Validation Rate) 通过率：两张图是同一个人，识别出也是同一个人</p>

<p>3.FRR(False Reject Rate) 拒真率：1-通过率，应该是本人但是人脸对比不通过，把真的认成假的</p>

<p>所有metrics都建立在阈值选取的基础上，跟阈值结合起来看才有业务上的意义</p>

<p>通常计算一定FAR下的VAL，比如facenet千分之一FAR下的VAL为98.64%</p>

<h1 id="feature-extract">feature extract</h1>

<h2 id="hoghistogram-of-oriented-gradients">HOG(Histogram of Oriented Gradients)</h2>

<p>https://www.learnopencv.com/histogram-of-oriented-gradients/</p>

<h1 id="deeplearning-loss-functions">DeepLearning Loss Functions</h1>

<h2 id="triplet-loss-facenet">Triplet Loss (FaceNet)</h2>

<p>a: anchor, p: positive, n: negitive</p>

<p>这里的\(f(x)\)是embedding</p>

<p>我希望a离p更近，且有一个margin，所以，</p>

\[||f(x_i^p) - f(x_i^a)||_2^2 + \alpha &lt; ||f(x_i^n) - f(x_i^a)||_2^2\]

<p>所以损失函数是，</p>

\[L = \sum\limits_{i=1}^m max(||f(x_i^p) - f(x_i^a)||_2^2 - ||f(x_i^n) - f(x_i^a)||_2^2 + \alpha, 0)\]

<h2 id="softmax-loss">Softmax Loss</h2>

<p>将人脸识别视作多分类问题</p>

<p>这里的\(f(x)\)是embedding</p>

\[L = -\frac{1}{m}\sum\limits_{i=1}^m log \frac{e^{W^T_{y_i}f(x_i) + b_{y_i}}}{\sum\limits_{j=1}^n e^{W^T_j f(x_i) + b_j}}\]

<h2 id="center-loss">Center Loss</h2>

<p>这里的\(f(x)\)是embedding</p>

<p>Softmax部分，即多分类问题的损失:</p>

\[L = -\frac{1}{m}\sum\limits_{i=1}^m log \frac{e^{W^T_{y_i}f(x_i) + b_{y_i}}}{\sum\limits_{j=1}^n e^{W^T_j f(x_i) + b_j}}\]

<p>Center部分，距离对应中心的距离：</p>

\[L_C = \frac{1}{2} \sum\limits_{i=1}^m ||f(x_i) - c_{y_i}||_2^2\]

<p>Center Loss的想法是，不仅在多分类问题上分得准，而且要更紧凑：</p>

\[L = L_S + \lambda L_C\]

<p>最后一个问题就是如何更新中心了：</p>

\[c_j^{t+1} = c_j^t - \alpha \Delta c_j^t\]

\[\Delta c_j = \frac{\sum\limits_{i=1}^m 1\{y_i=j\} (c_j - x_i)}{1 + \sum\limits_{i=1}^m 1\{y_i=j\}}\]

<p><img src="/MachineLearning/deep_learning/assets/face_recognition/center_loss.png" alt=""></p>

<p>论文链接：http://ydwen.github.io/papers/WenECCV16.pdf</p>

<h2 id="l-softmax-large-margin-softmax">L-Softmax (Large-Margin Softmax)</h2>

<p>这里的\(x\)是embedding</p>

<p>直观理解，当\(f(x)\)属于分类1，而不属于分类2时，Softmax想让\(W_1^Tx &gt;W_2^Tx\)，相当于\(\|W_1\| \|x\| cos(\theta_1) &gt; \|W_2\| \|x\| cos(\theta_2)\)</p>

<p>那么，L-Softmax想让这个条件更严格一些，\(\|W_1\| \|x\| cos(m\theta_1) &gt; \|W_2\| \|x\| cos(\theta_2), 0 \leq \theta_1 \leq \frac{\pi}{m}\)，也就是原本\(\theta_1\)达到的损失，现在\(\frac{\theta_1}{m}\)时就达到了，对于\(\theta_1\)的要求更高了</p>

<p>L-Softmax的定义：</p>

\[L_i = -log(\frac{e^{\|W_{y_i}\| \|x_i\| \phi(m\theta_{y_i})}}{e^{\|W_{y_i}\| \|x_i\| \phi(m\theta_{y_i})} + \sum\limits_{j \neq y_i} e^{\|W_j\| \|x_i\| cos(\theta_j)}})\]

<p>这里的\(\phi (\theta)\)的损失为：（具体公式参考论文）</p>

<p><img src="/MachineLearning/deep_learning/assets/face_recognition/L-Softmax-phi_theta.png" alt=""></p>

<p>论文链接：http://proceedings.mlr.press/v48/liud16.pdf</p>

<h2 id="a-softmax-angular-softmax-sphereface">A-Softmax (Angular Softmax, SphereFace)</h2>

<p>这里的\(x\)是embedding</p>

<p>A-Softmax在L-Softmax的基础上，限定了\(\|W\|=1, b = 0\)，则\(W_1^Tx + b = \|W_1\| \|x\| cos(\theta_1) + b = \|x\| cos(\theta_1)\)，每个图片的\(x\)是相同的，所以实际上就是比较\(cos(\theta)\)。\(\|W\|\)与\(x\)角度越小，则余弦值越大，则softmax后的值越大。也就是说，与真实类别角度越小，最后的softmax出来的概率越大，分类问题跟余弦距离就契合上了（这时我们可以使用余弦距离评判人脸距离，不必使用欧几里得距离了）</p>

<p>我们可以看到A-Softmax使的类间距更小了，不对\(\|W\|\)进行norm，可能会使\(\|W\|\)变大从而降低损失，而不是\(cos(\theta)\)变大而降低损失</p>

<p><img src="/MachineLearning/deep_learning/assets/face_recognition/A-Softmax-1.png" alt=""></p>

<p><img src="/MachineLearning/deep_learning/assets/face_recognition/A-Softmax-2.png" alt=""></p>

<p>A-Softmax的定义：</p>

\[L_i = -log(\frac{e^{\|x_i\| \phi(m\theta_{y_i})}}{e^{\|x_i\| \phi(m\theta_{y_i})} + \sum\limits_{j \neq y_i} e^{\|x_i\| cos(\theta_j)}})\]

<p>另外需要注意在实践中的\(m\)设置，由于\(m\)是一个非常强的限制，在\(m=2\)时，它会认为距离真实分类仍有\(2\theta\)的角度，所以比较难优化。实践中，可以使用softmax + \(\alpha\)倍的A-Softmax，刚开始\(\alpha=0\)，后面慢慢变大</p>

<p>论文链接：https://arxiv.org/pdf/1704.08063.pdf</p>

<h2 id="normface">NormFace</h2>

<p>这里的\(f\)是embedding</p>

<p>NormFace在Softmax基础上，将embedding向量和W都标准化了，还去掉了bias，这时候softmax更加贴近余弦相似度了，文章分析了为什么会更贴近余弦相似度以及训练中可能会出现的坑</p>

<p><strong>不进行norm的缺点</strong></p>

<p>可以看到下图是直接使用softmax进行训练，\(f_1\)与\(f_2\)是不同类，但是距离更近，而\(f_2\)跟\(f_3\)是同类，但距离更远</p>

<p>另外，分类色块趋向于放射状，是由于softmax会通过增加\(f\)的大小来降低损失</p>

<p><img src="/MachineLearning/deep_learning/assets/face_recognition/NormFace-Fig2.png" alt=""></p>

<p>如果我们不去掉bias，即\(\|b\|&gt;0\)，那么在原点附近就会有分类聚集</p>

<p><img src="/MachineLearning/deep_learning/assets/face_recognition/NormFace-Fig3.png" alt=""></p>

<p><strong>进行norm的问题：训练收敛失败</strong></p>

<p>单纯的将\(f\)，\(W\)都标准化，并取消bias，会无法收敛</p>

<p>原因是这样做会使\(Wx\)在\([-1, 1]\)之间，也就是\(\frac{e^{W^T_{y_i}f_i}}{\sum\limits_{j=1}^n e^{W^T_j f_i}}\)无法收敛到接近1，所以需要将\(Wx\)乘以一个倍数，来让它收敛</p>

<p>所以NormFace的损失为：
\(L_{S'} = -\frac{1}{m}\sum\limits_{i=1}^m log \frac{e^{sW^T_{y_i}f_i}}{\sum\limits_{j=1}^n e^{sW^T_j f_i}}\)</p>

<p>s的取值详情见论文（类数量会影响s的取值）</p>

<p><strong>跟欧几里得距离的关系</strong></p>

<p>由于\(\|x-y\|^2_2=2-2x^Ty\)，所以可以将损失写为，</p>

\[L_{S'} = -\frac{1}{m}\sum\limits_{i=1}^m log \frac{e^{sW^T_{y_i}f}}{\sum\limits_{j=1}^n e^{sW^T_j f}}
= -\frac{1}{m}\sum\limits_{i=1}^m log \frac{e^{-\frac{s}{2}\|f_i - W_{y_i}\|_2^2}}{\sum\limits_{j=1}^n e^{-\frac{s}{2}\|f_i - W_j\|_2^2}}\]

<p>所以这个时间余弦相似度跟欧几里得距离实质是一样的</p>

<p>我们可以将\(\|f_i - W_j\|_2^2\)带入到contrastive loss或者triplet loss中，这样就解决了这两种loss是使用欧几里得距离的问题了（不过要注意margin的设置，具体可见论文）</p>

<p>论文链接：https://arxiv.org/pdf/1704.06369.pdf</p>

<h2 id="am-softmax-additive-margin-softmax">AM-Softmax (Additive Margin Softmax)</h2>

<p>CosFace也是一样的思路</p>

<p>这里的\(f\)是embedding</p>

<p>AM-Softmax将\(f\)，\(W\)都标准化，并取消bias。特别的，它使用的margin方式是\(\phi(\theta) = cos(\theta) - m\)</p>

<p>所以最终的损失是：
\(\begin{aligned}
&amp; l_{AMS} = -log(\frac{e^{s\cdot (cos(\theta_{y_i}) - m)}}{e^{s\cdot (cos(\theta_{y_i}) - m)} + \sum\limits_{j \neq y_i} e^{s\cdot  cos(\theta_j)}}) \\
&amp; \qquad = -log(\frac{e^{s\cdot (W_{y_i}^T f - m)}}{e^{s\cdot (W_{y_i}^T f - m)} + \sum\limits_{j \neq y_i} e^{s\cdot  W_{j}^T f}}) \\
\end{aligned}\)</p>

<p>论文链接：https://arxiv.org/pdf/1801.05599.pdf</p>

<h2 id="arcface">ArcFace</h2>

<p>这里的\(f\)是embedding</p>

<p>ArcFace将\(f\)，\(W\)都标准化，并取消bias。它使用的margin方式是\(\phi(\theta) = cos(\theta - m)\)</p>

<p>所以最终的损失是：</p>

\[l = -log(\frac{e^{s\cdot (cos(\theta_{y_i} + m))}}{e^{s\cdot (cos(\theta_{y_i} + m))} + \sum\limits_{j \neq y_i} e^{s\cdot  cos(\theta_j)}})\]

<p>我们可以将A-Softmax、AM-Softmax（CosFace）、ArcFace结合在一起：</p>

\[l = -log(\frac{e^{s\cdot (cos(m_1\theta_{y_i} + m_2) - m_3)}}{e^{s\cdot (cos(m_1\theta_{y_i} + m_2) - m_3)} + \sum\limits_{j \neq y_i} e^{s\cdot  cos(\theta_j)}})\]

<p>这里对比一下三者在几何学上的差别</p>

<p><img src="/MachineLearning/deep_learning/assets/face_recognition/ArcFace-geo_diff.png" alt=""></p>

<p>论文链接：https://arxiv.org/pdf/1801.07698.pdf</p>


        </section>

        <aside id="sidebar">
          

          

          <p>This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</p>

          <p>由于笔记大部分来自于我之前的gitbook，可能会因为markdown规范不同导致公式显示错误，如果有显示错误请<a href="https://github.com/hahadsg/hahadsg.github.io/issues">找我</a>，感谢</p>
        </aside>
      </div>
    </div>

    
  </body>
</html>
